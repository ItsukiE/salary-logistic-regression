Previs√£o de Renda (Adult Census Dataset)

Este √© um projeto de Machine Learning para prever se a renda de um indiv√≠duo √© superior ou inferior a 50 mil d√≥lares anuais, com base em dados demogr√°ficos do censo dos EUA.

O objetivo principal foi praticar o processo completo de um projeto de Data Science: desde a limpeza e prepara√ß√£o dos dados (Data Cleaning e Feature Engineering) at√© o treinamento e avalia√ß√£o de um modelo de classifica√ß√£o.

üöÄ O Processo

O notebook salary.ipynb segue uma jornada clara de an√°lise e modelagem.

1. Limpeza e Prepara√ß√£o dos Dados (Passos 1 e 2)
O dataset original (adult11.csv) n√£o estava pronto para o modelo:

Valores Ausentes: Os valores ausentes estavam rotulados como ' ?' (com espa√ßos). Foi usada uma express√£o regular (r'\s*\?\s*') para localiz√°-los, substitu√≠-los por NaN e, em seguida, remover as linhas com dados faltantes.

Vari√°vel Alvo: A coluna alvo salary era um texto (' <=50K' e ' >50K'). Ela foi transformada em uma coluna num√©rica bin√°ria (salary_numeric), onde 0 representa <=50K e 1 representa >50K.

2. Engenharia de Features (Passo 3)
O modelo de Regress√£o Log√≠stica s√≥ aceita n√∫meros, mas o dataset possu√≠a 8 colunas de texto (categ√≥ricas), como workclass, occupation e marital-status.

One-Hot Encoding: Foi aplicada a t√©cnica One-Hot Encoding (usando pandas.get_dummies) para converter essas colunas categ√≥ricas em m√∫ltiplas colunas num√©ricas (0 ou 1).

Preven√ß√£o de Multicolinearidade: O par√¢metro drop_first=True foi usado para evitar a "Armadilha da Vari√°vel Dummy", garantindo a independ√™ncia das features.

3. Modelagem e Treinamento (Passo 4)
Com os dados 100% num√©ricos, o modelo p√¥de ser treinado.

Escolha do Modelo: Como o problema √© prever uma categoria (0 ou 1), o modelo ideal escolhido foi a Regress√£o Log√≠stica (LogisticRegression), que √© mais adequado para classifica√ß√£o do que a Regress√£o Linear.

Padroniza√ß√£o: As features foram padronizadas com StandardScaler. Isso √© crucial para modelos como a Regress√£o Log√≠stica, pois coloca todas as features (como age e capital-gain) na mesma escala, melhorando a performance e a velocidade de treinamento.

Divis√£o: Os dados foram divididos em 80% para treino e 20% para teste (train_test_split).

üìà Resultados
O modelo final de Regress√£o Log√≠stica alcan√ßou uma Acur√°cia (Accuracy) de 85.11% nos dados de teste.

O desempenho detalhado pode ser visto no Relat√≥rio de Classifica√ß√£o:

              precision    recall  f1-score   support

   <=50K (0)       0.88      0.93      0.90      6842
    >50K (1)       0.74      0.60      0.66      2203

    accuracy                           0.85      9045
   macro avg       0.81      0.77      0.78      9045
weighted avg       0.84      0.85      0.85      9045
Conclus√µes das M√©tricas:
Acur√°cia (85%): O modelo acerta a previs√£o de renda em 85% dos casos.

Precis√£o (Precision >50K = 0.74): De todas as vezes que o modelo previu que algu√©m ganhava >50K, ele estava correto 74% das vezes.

Recall (>50K = 0.60): O modelo conseguiu identificar corretamente 60% de todas as pessoas que realmente ganhavam >50K.
